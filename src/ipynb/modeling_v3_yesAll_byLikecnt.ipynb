{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/kakao-save-data/tag_song_dict_no0.json\n",
      "/kaggle/input/kakao-save-data/tag_song_dict.json\n",
      "/kaggle/input/kakao-save-data/__notebook__.ipynb\n",
      "/kaggle/input/kakao-save-data/custom.css\n",
      "/kaggle/input/kakao-save-data/song_tag_dict.json\n",
      "/kaggle/input/kakao-save-data/__results__.html\n",
      "/kaggle/input/kakao-save-data/__output__.json\n",
      "/kaggle/input/kakao-save-data/__results___files/__results___15_0.png\n",
      "/kaggle/input/hs-1-preprocess/__notebook__.ipynb\n",
      "/kaggle/input/hs-1-preprocess/custom.css\n",
      "/kaggle/input/hs-1-preprocess/__results__.html\n",
      "/kaggle/input/hs-1-preprocess/__output__.json\n",
      "/kaggle/input/hs-1-preprocess/train_DF.parquet\n",
      "/kaggle/input/hs-1-preprocess/__results___files/__results___9_0.png\n",
      "/kaggle/input/hs-1-preprocess/__results___files/__results___10_0.png\n",
      "/kaggle/input/hs-1-preprocess/__results___files/__results___7_0.png\n",
      "/kaggle/input/hs-1-preprocess/__results___files/__results___11_0.png\n",
      "/kaggle/input/kakao-arena-melon/genre_gn_all.json\n",
      "/kaggle/input/kakao-arena-melon/val.json\n",
      "/kaggle/input/kakao-arena-melon/train.json\n",
      "/kaggle/input/kakao-arena-melon/song_meta.json\n",
      "/kaggle/input/kakao-arena-melon/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from collections import Counter\n",
    "import math, json, io\n",
    "import distutils.dir_util\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "    return json_obj\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(parent)\n",
    "    with io.open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_path = '/kaggle/input/kakao-arena-melon/'\n",
    "\n",
    "### genre_gn_all\n",
    "# genre_gn_all = pd.read_json(kaggle_path+'genre_gn_all.json', typ = 'series')\n",
    "# genre_gn_all = pd.DataFrame(genre_gn_all, columns = ['gnr_name']).reset_index().rename(columns = {'index' : 'gnr_code'})\n",
    "\n",
    "### song_meta\n",
    "song_meta = pd.read_json(kaggle_path+'song_meta.json', typ = 'frame')\n",
    "\n",
    "### modeling_data\n",
    "train = pd.read_json(kaggle_path+'train.json', typ = 'frame')\n",
    "val = pd.read_json(kaggle_path+'val.json', typ = 'frame')\n",
    "# test = pd.read_json(kaggle_path+'test.json', typ = 'frame')\n",
    "\n",
    "train_pv = pd.read_parquet('/kaggle/input/hs-1-preprocess/train_DF.parquet')\n",
    "song_tag_dict = load_json('/kaggle/input/kakao-save-data/song_tag_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# index2id = {i:u for i, u in enumerate((train_pv.index))}\n",
    "# id2index = {u:i for i, u in enumerate((train_pv.index))}\n",
    "# # train_pv.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>85</th>\n",
       "      <th>107</th>\n",
       "      <th>164</th>\n",
       "      <th>217</th>\n",
       "      <th>228</th>\n",
       "      <th>307</th>\n",
       "      <th>325</th>\n",
       "      <th>347</th>\n",
       "      <th>545</th>\n",
       "      <th>577</th>\n",
       "      <th>...</th>\n",
       "      <th>153005</th>\n",
       "      <th>153010</th>\n",
       "      <th>153051</th>\n",
       "      <th>153070</th>\n",
       "      <th>153074</th>\n",
       "      <th>153075</th>\n",
       "      <th>153187</th>\n",
       "      <th>153242</th>\n",
       "      <th>153280</th>\n",
       "      <th>153333</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2703 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id     85  107  164  217  228  307  325  347  545  577  ...  153005  153010  \\\n",
       "song                                                    ...                   \n",
       "10    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "62    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "71    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "93    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "195   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "\n",
       "id    153051  153070  153074  153075  153187  153242  153280  153333  \n",
       "song                                                                  \n",
       "10       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "62       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "71       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "93       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "195      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 2703 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11065, 2703)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "song\n",
       "10         6.0\n",
       "62        11.0\n",
       "71        14.0\n",
       "93         5.0\n",
       "195        7.0\n",
       "          ... \n",
       "707724    25.0\n",
       "707768     7.0\n",
       "707837    17.0\n",
       "707849     5.0\n",
       "707873     6.0\n",
       "Length: 11065, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_pv.shape)\n",
    "train_pv.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_pv.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.0573\n",
      "Epoch 2/5\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.0037\n",
      "Epoch 3/5\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0037\n",
      "Epoch 4/5\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.0037\n",
      "Epoch 5/5\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "a = 1000\n",
    "b = 500\n",
    "\n",
    "input_img = Input(shape=(input_dim,)) ## input layer\n",
    "encoded = Dense(a, activation='relu')(input_img) ## encoding dim으로 압축\n",
    "encoded = Dense(b, activation='relu')(encoded) ## encoding dim으로 압축\n",
    "\n",
    "\n",
    "decoded = Dense(b, activation='sigmoid')(encoded) ## input dim으로 복귀\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded) ## input dim으로 복귀\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input01\n",
    "# encoded_input = Input(shape=(encoding_dim,))\n",
    "encoded_input = Input(shape=(b,))\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# compile\n",
    "autoencoder.compile(optimizer='adam', loss='mse') # (optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "## train\n",
    "tmp = train_pv.values\n",
    "history = autoencoder.fit(tmp, tmp,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(tmp)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(data=encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_array = cosine_similarity(train_data, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular(playlists, col, topk_count):\n",
    "    c = Counter()\n",
    "\n",
    "    for doc in playlists[col]:\n",
    "        c.update(doc)\n",
    "\n",
    "    topk = c.most_common(topk_count)\n",
    "    return c, [k for k, v in topk]\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    ## 데이터에 l의 원소가 없으면 l의 원소를 채워 넣는다. \n",
    "    return [x for x in l if not (x in seen)]\n",
    "\n",
    "def check_target_type(df):\n",
    "    no_song_idx = []\n",
    "    no_tag_idx  = []\n",
    "    no_both_idx = []\n",
    "    yes_all_idx = []\n",
    "\n",
    "    for i in df.index:\n",
    "        ## 노래 X 태그 O\n",
    "        if   bool(not df.loc[i:i, 'songs'].values[0]) & bool(df.loc[i:i, 'tags'].values[0]):\n",
    "            no_song_idx.append(i)\n",
    "        ## 노래 O 태그 X\n",
    "        elif bool(df.loc[i:i, 'songs'].values[0])     & bool(not df.loc[i:i, 'tags'].values[0]):\n",
    "            no_tag_idx.append(i)  \n",
    "        ## 노래 X 태그 X\n",
    "        elif bool(not df.loc[i:i, 'songs'].values[0]) & bool(not df.loc[i:i, 'tags'].values[0]):\n",
    "            no_both_idx.append(i)          \n",
    "        ## 노래 O 태그 O (노래 or 태그 일부 누락)\n",
    "        else:\n",
    "            yes_all_idx.append(i)\n",
    "            \n",
    "    print(\"노래 X 태그 O : {}개\".format(len(no_song_idx)))\n",
    "    print(\"노래 O 태그 X : {}개\".format(len(no_tag_idx)))\n",
    "    print(\"노래 X 태그 X : {}개\".format(len(no_both_idx)))\n",
    "    print(\"노래 O 태그 O : {}개\".format(len(yes_all_idx)))\n",
    "    \n",
    "    return no_song_idx, no_tag_idx, no_both_idx, yes_all_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노래 X 태그 O : 2630개\n",
      "노래 O 태그 X : 9661개\n",
      "노래 X 태그 X : 1749개\n",
      "노래 O 태그 O : 8975개\n"
     ]
    }
   ],
   "source": [
    "no_song_idx, no_tag_idx, no_both_idx, yes_all_idx = check_target_type(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['updt_date'].apply(lambda x: int(x[2:4]))\n",
    "val['year'] = val['updt_date'].apply(lambda x: int(x[2:4]))\n",
    "\n",
    "year_list = list(train['year'].unique())\n",
    "year_list = sorted(year_list)\n",
    "\n",
    "val3 = val[val.index.isin(yes_all_idx)]\n",
    "\n",
    "percent=0.975\n",
    "like_try = train['like_cnt'].quantile(percent)\n",
    "\n",
    "# train_tmp = train[train['like_cnt'] > like_try]\n",
    "val_tmp = val3[val3['like_cnt'] > like_try]\n",
    "# val_tmp = val3[val3['year'].isin(small_years)]\n",
    "# print(\"val year shape\", val_tmp.shape)\n",
    "# val_tmp.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_year = []\n",
    "for i in year_list:\n",
    "    tmp = train[train['year'] == i]\n",
    "    _, year_song = most_popular(tmp, \"songs\", 200)\n",
    "    _, year_tag = most_popular(tmp, \"tags\", 100)\n",
    "    popular_year.append({\n",
    "        \"year\" : i,\n",
    "        \"songs\" : year_song,\n",
    "        \"tags\" : year_tag,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val3_predict = []\n",
    "val_tmp = val3.copy()\n",
    "for i in val_tmp.index:\n",
    "    year = val_tmp.loc[i]['year']\n",
    "\n",
    "    ################ song 채우기 ###############################\n",
    "    songs = val_tmp.loc[i]['songs']\n",
    "    songs = [s for s in songs if s in train_pv.index]\n",
    "    if len(songs):\n",
    "        len_song = math.ceil(round(200/len(songs),2))\n",
    "        cur_song = []\n",
    "        for s in songs:\n",
    "            s_idx = train_pv.index.tolist().index(s)\n",
    "            to_d = list(np.argsort(-cosine_array[s_idx])[1:1+len_song])            \n",
    "#             to_update = [index2id[x] for x in to_d]\n",
    "            cur_song = remove_seen(cur_song, to_d)\n",
    "        cur_song = cur_song[:200]\n",
    "\n",
    "    else:\n",
    "        ## 부족하면 채워준다.\n",
    "        cur_song = popular_year[year-4]['songs']\n",
    "\n",
    "    cur_song = remove_seen(list(val_tmp.loc[i:i, 'songs'])[0], cur_song)[:100]\n",
    "    \n",
    "    #중복 케이스 때문에 부족하면 popular song으로 다시 채워줌\n",
    "    if len(cur_song) != 100:\n",
    "        update_song = remove_seen(cur_song, popular_year[year-4]['songs'])\n",
    "        cur_song.extend(update_song)\n",
    "        cur_song = cur_song[:200]\n",
    "    \n",
    "    \n",
    "    ############### tag 채우기 ##################################\n",
    "    tag_counter = Counter()\n",
    "    for song in list(val_tmp.loc[i:i, 'songs'].values[0]):\n",
    "        if str(song) in song_tag_dict:\n",
    "            for tag in song_tag_dict[str(song)]:\n",
    "                tag_counter.update({tag : 1})\n",
    "    tag_counter = sorted(tag_counter.items(), key= lambda x:x[1], reverse = True)        \n",
    "    tag_counter = tag_counter[:100] ## 넉넉히 100개 잡는다. \n",
    "    \n",
    "    cur_tag = []\n",
    "    for k in tag_counter:\n",
    "        cur_tag.append(k[0])     \n",
    "        \n",
    "    if (len(cur_tag) < 100) & (len(cur_tag) > 0 ):\n",
    "        ## 부족하면 채워준다.\n",
    "        update_tag = remove_seen(cur_tag, popular_year[year-4]['tags'])\n",
    "        cur_tag.extend(update_tag)\n",
    "        cur_tag = cur_tag[:100]\n",
    "    if len(cur_tag) == 0:\n",
    "        cur_tag = popular_year[year-4]['tags'][:100]\n",
    "        \n",
    "    #############################################################    \n",
    "\n",
    "    val3_predict.append({\n",
    "        \"id\" : list(val_tmp.loc[i:i, 'id'])[0],\n",
    "        \"songs\": remove_seen(list(val_tmp.loc[i:i, 'songs'])[0], cur_song)[:100],\n",
    "        \"tags\": remove_seen(list(val_tmp.loc[i:i, 'tags'])[0], cur_tag)[:10],\n",
    "     })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8975"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(val3_predict, 'val3_predict_with_like.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
