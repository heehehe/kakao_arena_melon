{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/src/script.ipynb\n",
      "/kaggle/lib/kaggle/gcp.py\n",
      "/kaggle/input/kakao-arena-melon/train.json\n",
      "/kaggle/input/kakao-arena-melon/test.json\n",
      "/kaggle/input/kakao-arena-melon/genre_gn_all.json\n",
      "/kaggle/input/kakao-arena-melon/song_meta.json\n",
      "/kaggle/input/kakao-arena-melon/val.json\n",
      "/kaggle/input/make-pv-file/__results__.html\n",
      "/kaggle/input/make-pv-file/__notebook__.ipynb\n",
      "/kaggle/input/make-pv-file/custom.css\n",
      "/kaggle/input/make-pv-file/train_DF.parquet\n",
      "/kaggle/input/make-pv-file/__output__.json\n",
      "/kaggle/input/kakao-train-valid-split/train_y.json\n",
      "/kaggle/input/kakao-train-valid-split/train_df.json\n",
      "/kaggle/input/kakao-train-valid-split/val_x.json\n",
      "/kaggle/input/kakao-train-valid-split/__results__.html\n",
      "/kaggle/input/kakao-train-valid-split/__notebook__.ipynb\n",
      "/kaggle/input/kakao-train-valid-split/train_x.json\n",
      "/kaggle/input/kakao-train-valid-split/custom.css\n",
      "/kaggle/input/kakao-train-valid-split/__output__.json\n",
      "/kaggle/input/kakao-train-valid-split/val_y.json\n",
      "/kaggle/input/kakao-train-valid-split/val_df.json\n",
      "/kaggle/input/kakao-save-song-tag-dict/__results__.html\n",
      "/kaggle/input/kakao-save-song-tag-dict/song_tag_dict.json\n",
      "/kaggle/input/kakao-save-song-tag-dict/tag_song_dict.json\n",
      "/kaggle/input/kakao-save-song-tag-dict/tag_song_dict_no0.json\n",
      "/kaggle/input/kakao-save-song-tag-dict/__notebook__.ipynb\n",
      "/kaggle/input/kakao-save-song-tag-dict/custom.css\n",
      "/kaggle/input/kakao-save-song-tag-dict/__output__.json\n",
      "/kaggle/input/kakao-save-song-tag-dict/__results___files/__results___15_0.png\n",
      "/kaggle/working/__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import io\n",
    "import distutils.dir_util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import math\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "        \n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "from keras.initializers import glorot_normal, Zeros, Ones\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(parent)\n",
    "    with io.open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('/kaggle/input/kakao-arena-melon/train.json')\n",
    "train_pv = pd.read_parquet('/kaggle/input/make-pv-file/train_DF.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# song_meta = pd.read_json('/kaggle/input/kakao-arena-melon/song_meta.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# song_meta['issue_year'] = song_meta['issue_date'].apply(lambda x: str(x)[2:4])\n",
    "\n",
    "# id_year_dict = pd.Series(song_meta.issue_year.values, index=song_meta.id).to_dict()\n",
    "# del song_meta\n",
    "# gc.collect()\n",
    "# train_pv.reset_index(inplace = True)\n",
    "# train_pv['year'] = train_pv['song'].apply(lambda x :id_year_dict[x])\n",
    "# train_pv['year'] = pd.to_numeric(train_pv['year'],errors='coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = train_pv['year'].values.reshape(-1,1) #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# x = pd.DataFrame(x_scaled)\n",
    "# train_pv['year'] = x\n",
    "\n",
    "\n",
    "# train_pv.set_index('song', inplace = True)\n",
    "\n",
    "# del song_meta, x\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index2id = {i:u for i, u in enumerate((train_pv.index))}\n",
    "# id2index = {u:i for i, u in enumerate((train_pv.index))}\n",
    "# train_pv.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34242, 18074)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>6</th>\n",
       "      <th>25</th>\n",
       "      <th>39</th>\n",
       "      <th>50</th>\n",
       "      <th>55</th>\n",
       "      <th>85</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>112</th>\n",
       "      <th>127</th>\n",
       "      <th>...</th>\n",
       "      <th>153265</th>\n",
       "      <th>153275</th>\n",
       "      <th>153280</th>\n",
       "      <th>153288</th>\n",
       "      <th>153332</th>\n",
       "      <th>153347</th>\n",
       "      <th>153364</th>\n",
       "      <th>153388</th>\n",
       "      <th>153421</th>\n",
       "      <th>153428</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 18074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id      6   25   39   50   55   85  106  107  112  127  ...  153265  153275  \\\n",
       "song                                                    ...                   \n",
       "10    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "17    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "\n",
       "id    153280  153288  153332  153347  153364  153388  153421  153428  \n",
       "song                                                                  \n",
       "10       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "17       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[2 rows x 18074 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>6</th>\n",
       "      <th>25</th>\n",
       "      <th>39</th>\n",
       "      <th>50</th>\n",
       "      <th>55</th>\n",
       "      <th>85</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>112</th>\n",
       "      <th>127</th>\n",
       "      <th>...</th>\n",
       "      <th>153265</th>\n",
       "      <th>153275</th>\n",
       "      <th>153280</th>\n",
       "      <th>153288</th>\n",
       "      <th>153332</th>\n",
       "      <th>153347</th>\n",
       "      <th>153364</th>\n",
       "      <th>153388</th>\n",
       "      <th>153421</th>\n",
       "      <th>153428</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707913</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 18074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id        6   25   39   50   55   85  106  107  112  127  ...  153265  153275  \\\n",
       "song                                                      ...                   \n",
       "707913  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "707949  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
       "\n",
       "id      153280  153288  153332  153347  153364  153388  153421  153428  \n",
       "song                                                                    \n",
       "707913     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "707949     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[2 rows x 18074 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_pv.shape)\n",
    "display(train_pv.head(2))\n",
    "display(train_pv.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "# encoding_dim = 200  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# intput size\n",
    "input_dim = train_pv.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_train = train_pv.values\n",
    "\n",
    "# noise_factor = 0.5\n",
    "# x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "# # x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "# x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "# # x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 10000\n",
    "# b = 5000\n",
    "# c = 500\n",
    "# input_dim = train_pv.shape[1]\n",
    "# model = Sequential()\n",
    "# model.add(Dense(a, activation='relu', input_dim=input_dim))\n",
    "# model.add(Dense(b, activation='relu'))\n",
    "# model.add(Dense(c, activation='relu'))\n",
    "# model.add(Dense(b, activation='relu'))\n",
    "# model.add(Dense(a, activation='relu'))\n",
    "# model.add(Dense(input_dim, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_noisy, x_train, \n",
    "#           nb_epoch=5,\n",
    "#           batch_size=256,\n",
    "#           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34242/34242 [==============================] - 167s 5ms/step - loss: 0.0283\n",
      "Epoch 2/5\n",
      "34242/34242 [==============================] - 161s 5ms/step - loss: 0.0013\n",
      "Epoch 3/5\n",
      "34242/34242 [==============================] - 163s 5ms/step - loss: 0.0013\n",
      "Epoch 4/5\n",
      "34242/34242 [==============================] - 171s 5ms/step - loss: 0.0013\n",
      "Epoch 5/5\n",
      "34242/34242 [==============================] - 162s 5ms/step - loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "a = 1000\n",
    "b = 500\n",
    "\n",
    "input_img = Input(shape=(input_dim,)) ## input layer\n",
    "encoded = Dense(a, activation='relu')(input_img) ## encoding dim으로 압축\n",
    "encoded = Dense(b, activation='relu')(encoded) ## encoding dim으로 압축\n",
    "\n",
    "\n",
    "decoded = Dense(b, activation='sigmoid')(encoded) ## input dim으로 복귀\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded) ## input dim으로 복귀\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input01\n",
    "# encoded_input = Input(shape=(encoding_dim,))\n",
    "encoded_input = Input(shape=(b,))\n",
    "\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# compile\n",
    "autoencoder.compile(optimizer='adam', loss='mse') # (optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "## train\n",
    "tmp = train_pv.values\n",
    "history = autoencoder.fit(tmp, tmp,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(tmp)\n",
    "# decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "del input_img, autoencoder, encoder, encoded_input, decoder_layer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tmp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(data=encoded_imgs)\n",
    "\n",
    "del encoded_imgs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/34242 [00:00<04:01, 141.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_array complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34242/34242 [03:30<00:00, 162.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_array = cosine_similarity(train_data, train_data)\n",
    "print('cosine_array complete')\n",
    "# item_based_array= pd.DataFrame(data = cosine_array, index = train_pv.index, columns = train_pv.index)\n",
    "\n",
    "\n",
    "index2id = {i:u for i, u in enumerate((train_pv.index))}\n",
    "\n",
    "cf_dict = {}\n",
    "for i in tqdm(range(len(cosine_array))):\n",
    "    song_id= list(map(index2id.get, list(np.argsort(-cosine_array[i])[1:201])))\n",
    "    value= list(np.sort(cosine_array[0])[::-1][1:201])\n",
    "    cf_dict[index2id[i]] = list(zip(song_id,value))\n",
    "\n",
    "del cosine_array, train_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cosine_array[2][:5])\n",
    "# print(np.argsort(-cosine_array[2])[:5])\n",
    "# t= np.argsort(-cosine_array[2])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_meta[song_meta['id'].isin([62,366786,116573])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 본격 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular(playlists, col, topk_count):\n",
    "    c = Counter()\n",
    "\n",
    "    for doc in playlists[col]:\n",
    "        c.update(doc)\n",
    "\n",
    "    topk = c.most_common(topk_count)\n",
    "    return c, [k for k, v in topk]\n",
    "\n",
    "def remove_seen(seen, l):\n",
    "    seen = set(seen)\n",
    "    ## 데이터에 l의 원소가 없으면 l의 원소를 채워 넣는다. \n",
    "    return [x for x in l if not (x in seen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('/kaggle/input/kakao-arena-melon/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_target_type(val):\n",
    "    no_song = []\n",
    "    no_both = []\n",
    "    no_tag = []\n",
    "    yes_index = []\n",
    "\n",
    "    for i in range(len(val)):\n",
    "        if (not val.loc[i:i, 'songs'].values[0])&(not not val.loc[i:i, 'tags'].values[0]): ## 노래는 없는데 태그는 있어\n",
    "            no_song.append(i)\n",
    "\n",
    "        elif (not not val.loc[i:i, 'songs'].values[0]) & (not val.loc[i:i, 'tags'].values[0]): ## 노래는 있는데 태그가 없으\n",
    "            no_tag.append(i)  \n",
    "\n",
    "        elif (not val.loc[i:i, 'songs'].values[0]) & (not val.loc[i:i, 'tags'].values[0]): ## 노래도 없고 태그도 없어\n",
    "            no_both.append(i)          \n",
    "\n",
    "        else: ## 둘다 있음, 아마도 노래 몇 곡이 누락 됐어 \n",
    "            yes_index.append(i)\n",
    "            \n",
    "    print(\"노래가 하나도 없음 : \", len(no_song))\n",
    "    print(\"노래, 태그 둘 다 존재함 : \", len(yes_index))\n",
    "    print(\"태그가 없음 : \",len(no_tag) )\n",
    "    print(\"둘다 없음 : \", len(no_both))\n",
    "    \n",
    "    return no_song, no_both, no_tag, yes_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노래가 하나도 없음 :  2630\n",
      "노래, 태그 둘 다 존재함 :  8975\n",
      "태그가 없음 :  9661\n",
      "둘다 없음 :  1749\n"
     ]
    }
   ],
   "source": [
    "no_song, no_both, no_tag, yes_index = check_target_type(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 3. 둘 다 있음\n",
    "- 기존에 존재하던 tag에서 가장 빈번하게 나타났던 음악을 넣어주기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val year shape (6401, 7)\n"
     ]
    }
   ],
   "source": [
    "train['year'] = train['updt_date'].apply(lambda x: int(x[2:4]))\n",
    "val['year'] = val['updt_date'].apply(lambda x: int(x[2:4]))\n",
    "\n",
    "\n",
    "year_list = list(train['year'].unique())\n",
    "year_list= sorted(year_list)\n",
    "\n",
    "val3 = val[val.index.isin(yes_index)]\n",
    "\n",
    "\n",
    "small_years = [17,18,19,20]\n",
    "\n",
    "val_tmp = val3[val3['year'].isin(small_years)]\n",
    "print(\"val year shape\", val_tmp.shape)\n",
    "val_tmp.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_year = []\n",
    "for i in year_list:\n",
    "    tmp = train[train['year'] == i]\n",
    "    _, year_song = most_popular(tmp, \"songs\", 200)\n",
    "    _, year_tag = most_popular(tmp, \"tags\", 100)\n",
    "    popular_year.append({\n",
    "        \"year\" : i,\n",
    "        \"songs\" : year_song,\n",
    "        \"tags\" : year_tag,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tag_dict = load_json('/kaggle/input/kakao-save-song-tag-dict/song_tag_dict.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f7(seq):\n",
    "    '''\n",
    "    list에 있는 중복 데이터는 삭제하고, 순서는 유지하는 함수\n",
    "    set만 사용하면 순서가 뒤엉키게 됨\n",
    "    '''\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val3_predict = []\n",
    "for i in range(len(val_tmp)):\n",
    "    year = val_tmp.loc[i:i, 'year'].values[0]\n",
    "    \n",
    "    \n",
    "    ################ song 채우기 ###############################\n",
    "    songs = val_tmp.loc[i:i, 'songs'].values[0]\n",
    "    songs = [x for x in songs if x in cf_dict]\n",
    "\n",
    "    if len(songs):\n",
    "        tmp_list = []\n",
    "        for song in songs:\n",
    "            tmp_list.extend(cf_dict[song]) \n",
    "        tmp_list.sort(key = lambda x: x[1], reverse = True)    \n",
    "        tmp_list = [i[0] for i in tmp_list if i[1]>0]\n",
    "        tmp_list = f7(tmp_list)\n",
    "\n",
    "        cur_song = tmp_list[:200]\n",
    "    else:\n",
    "        cur_song = popular_year[year-4]['songs']\n",
    "\n",
    "    cur_song = remove_seen(list(val_tmp.loc[i:i, 'songs'])[0], cur_song)[:100]\n",
    "\n",
    "    #중복 케이스 때문에 부족하면 popular song으로 다시 채워줌\n",
    "    if len(cur_song) != 100:\n",
    "        update_song = remove_seen(cur_song, popular_year[year-4]['songs'])\n",
    "        cur_song.extend(update_song)\n",
    "        cur_song = cur_song[:200]\n",
    "    \n",
    "    \n",
    "    ############### tag 채우기 ##################################\n",
    "    tag_counter = Counter()\n",
    "    for song in list(val_tmp.loc[i:i, 'songs'].values[0]):\n",
    "        if str(song) in song_tag_dict:\n",
    "            for tag in song_tag_dict[str(song)]:\n",
    "                tag_counter.update({tag : 1})\n",
    "    tag_counter = sorted(tag_counter.items(), key= lambda x:x[1], reverse = True)        \n",
    "    tag_counter = tag_counter[:100] ## 넉넉히 100개 잡는다. \n",
    "    \n",
    "    cur_tag = []\n",
    "    for k in tag_counter:\n",
    "        cur_tag.append(k[0])     \n",
    "        \n",
    "    if (len(cur_tag) < 100) & (len(cur_tag) > 0 ):\n",
    "        ## 부족하면 채워준다.\n",
    "        update_tag = remove_seen(cur_tag, popular_year[year-4]['tags'])\n",
    "        cur_tag.extend(update_tag)\n",
    "        cur_tag = cur_tag[:100]\n",
    "    if len(cur_tag) == 0:\n",
    "        cur_tag = popular_year[year-4]['tags'][:100]\n",
    "        \n",
    "    #############################################################    \n",
    "\n",
    "    val3_predict.append({\n",
    "        \"id\" : list(val_tmp.loc[i:i, 'id'])[0],\n",
    "        \"songs\": remove_seen(list(val_tmp.loc[i:i, 'songs'])[0], cur_song)[:100],\n",
    "        \"tags\": remove_seen(list(val_tmp.loc[i:i, 'tags'])[0], cur_tag)[:10],\n",
    "     })    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_json(val3_predict, 'val3_2019_predict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "# FileLink(r'val3_2015_predict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
