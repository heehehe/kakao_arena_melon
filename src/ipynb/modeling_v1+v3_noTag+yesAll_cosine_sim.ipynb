{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 14년"},{"metadata":{"trusted":true},"cell_type":"code","source":"small_years =  [14]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport copy\nimport json\nimport random\nimport io\nimport distutils.dir_util\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy.sparse.linalg import svds\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport os, sys, gc, time, warnings, pickle, psutil, random\nimport gc\nimport time\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n        \nfrom collections import Counter\nfrom tqdm import tqdm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_json(fname):\n    with open(fname, encoding=\"utf-8\") as f:\n        json_obj = json.load(f)\n\n    return json_obj\n\ndef write_json(data, fname):\n    def _conv(o):\n        if isinstance(o, (np.int64, np.int32)):\n            return int(o)\n        raise TypeError\n\n    parent = os.path.dirname(fname)\n    distutils.dir_util.mkpath(parent)\n    with io.open(fname, \"w\", encoding=\"utf-8\") as f:\n        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n        f.write(json_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_parquet('/kaggle/input/song-traim-song-tag-dict-tag-song-dict/train(song_trim).parquet')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = pd.read_json('/kaggle/input/song-traim-song-tag-dict-tag-song-dict/test(lower).json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def most_popular(playlists, col, topk_count):\n    c = Counter()\n\n    for doc in playlists[col]:\n        c.update(doc)\n\n    topk = c.most_common(topk_count)\n    return c, [k for k, v in topk]\n\ndef remove_seen(seen, l):\n    seen = set(seen)\n    ## 데이터에 l의 원소가 없으면 l의 원소를 채워 넣는다. \n    return [x for x in l if not (x in seen)]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def check_target_type(val):\n    no_song = []\n    no_both = []\n    no_tag = []\n    yes_index = []\n\n    for i in range(len(val)):\n        if (not val.loc[i:i, 'songs'].values[0])&(not not val.loc[i:i, 'tags'].values[0]): ## 노래는 없는데 태그는 있어\n            no_song.append(i)\n\n        elif (not not val.loc[i:i, 'songs'].values[0]) & (not val.loc[i:i, 'tags'].values[0]): ## 노래는 있는데 태그가 없으\n            no_tag.append(i)  \n\n        elif (not val.loc[i:i, 'songs'].values[0]) & (not val.loc[i:i, 'tags'].values[0]): ## 노래도 없고 태그도 없어\n            no_both.append(i)          \n\n        else: ## 둘다 있음, 아마도 노래 몇 곡이 누락 됐어 \n            yes_index.append(i)\n            \n    print(\"노래가 하나도 없음 : \", len(no_song))\n    print(\"노래, 태그 둘 다 존재함 : \", len(yes_index))\n    print(\"태그가 없음 : \",len(no_tag) )\n    print(\"둘다 없음 : \", len(no_both))\n    \n    return no_song, no_both, no_tag, yes_index\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_song, no_both, no_tag, yes_index = check_target_type(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v1v3_index= yes_index+ no_tag\n\n\ntrain['year'] = train['updt_date'].apply(lambda x: int(x[2:4]))\ntrain['date'] = train['updt_date'].apply(lambda x: int(str(x[2:4]) + str(x[5:7])) )\n\nval['year'] = val['updt_date'].apply(lambda x: int(x[2:4]))\nval['date'] = val['updt_date'].apply(lambda x: int(str(x[2:4]) + str(x[5:7])) )\n\n\nyear_list = list(train['year'].unique())\nyear_list= sorted(year_list)\n\nv1v3 = val[val.index.isin(v1v3_index)]\n\n\nval_tmp = v1v3[v1v3['year'].isin(small_years)]\nprint(\"val year shape\", val_tmp.shape)\nval_tmp.reset_index(inplace = True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_list = list(train['date'].unique())\ndate_list= sorted(date_list)\n\ndate_dict = {}\nfor i,k in enumerate(date_list):\n    date_dict[k] = i\n\npopular_date_tag = []\nfor i in range(len(date_list)):\n    if i <= 13:  ## 13이전에는 한 달에 100개가 안나옴\n        year = int(str(date_list[i])[0]) ## year\n        tmp = train[train['year'] == year]\n        _, year_tag = most_popular(tmp, \"tags\", 100)\n        popular_date_tag.append({\n            \"date\" : date_list[i],\n            \"tags\" : year_tag,})\n        \n    else:\n        tmp = train[train['date'] == date_list[i]]\n        _, date_tag = most_popular(tmp, \"tags\", 100)\n        popular_date_tag.append({\n            \"date\" : date_list[i],\n            \"tags\" : date_tag,})  \n        \n        \npopular_date_song = []\nfor i in range(len(date_list)):\n    if i <= 9:  ## 11이전에는 한 달에 100개가 안나옴\n        year = int(str(date_list[i])[0]) ## year\n        tmp = train[train['year'] == year]\n        _, date_song = most_popular(tmp, \"songs\", 200)\n        popular_date_song.append({\n            \"date\" : date_list[i],\n            \"songs\" : date_song,})               \n        \n    else:\n        tmp = train[train['date'] == date_list[i]]\n        _, date_song = most_popular(tmp, \"songs\", 200)\n        popular_date_song.append({\n            \"date\" : date_list[i],\n            \"songs\" : date_song,})          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = train[(train['year'].isin(small_years))]\nlike_num = int(np.percentile(tmp['like_cnt'], 70))\ntmp = tmp[(tmp['like_cnt'] >like_num)]\ntmp.reset_index(inplace = True, drop = True)\nprint(\"train best playlist\", tmp.shape)\nprint('train+valid = ', tmp.shape[0]+val_tmp.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"song_tag_dict = load_json('/kaggle/input/song-traim-song-tag-dict-tag-song-dict/song_tag_dict.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def before_pivot(data):\n    result = []\n    for i in tqdm(range(len(data))):\n        for song in data.loc[i:i, 'songs'].values[0]:\n            df = pd.DataFrame({\n                        'id' : [data.loc[i:i, 'id'].values[0]],\n                        'song' : [song],\n                        'point' : 1\n                    })\n            result += [df]\n\n    final_result = pd.concat(result)\n    print(final_result.shape)\n    return final_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"before_tmp = before_pivot(tmp)\n\n## train만 1보다 작은 노래는 없애준다.\ntmp_dict = before_tmp['song'].value_counts().to_dict()\nbefore_tmp['count']= before_tmp['song'].apply(lambda x : tmp_dict[x])\nbefore_tmp = before_tmp[before_tmp['count'] > 1]\nprint(before_tmp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"before_val_tmp = before_pivot(val_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_result = pd.concat([before_tmp, before_val_tmp])\ndel before_tmp, before_val_tmp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def make_cosine_predict(final_result):\n    R_df = final_result.pivot(index = 'id', columns ='song', values = 'point').fillna(0)\n    del final_result\n    \n    print(\"make cosine data\")    \n    cosine_array = cosine_similarity(R_df, R_df)\n    predicted_array = np.zeros(shape=(len(R_df.index),len(R_df.columns))) \n    for i in tqdm(range(len(cosine_array))):\n        top_200 = cosine_array[i].argsort()[-201:][::-1]\n        top_200 = np.delete(top_200, 0)\n\n        weighted_sum = np.array([0])\n        for top_idx in top_200:\n            weighted_sum = weighted_sum + (cosine_array[i][top_idx] * R_df.values[top_idx])\n        predicted = weighted_sum / len(top_200)\n        predicted_array[i] = predicted\n    iu_predicted = R_df.values*(-99999) + predicted_array\n    \n    print(\"make dic data\")    \n    cf_dic = {}\n    for i in range(len(iu_predicted)):\n        cf_dic[R_df.index[i]] = R_df.columns[iu_predicted[i].argsort()[-200:][::-1]].tolist()\n    \n    return cf_dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cf_dic = make_cosine_predict(final_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"val_tmp.reset_index(inplace = True, drop = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"val_tmp.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"val1_predict = []\nfor i in range(len(val_tmp)):\n    ############### song 채우기 ##################################\n    date = date_dict[val_tmp.loc[i:i, 'date'].values[0]]\n    row_number = val_tmp.loc[i:i, 'id'].values[0]\n    cur_song = list(cf_dic[row_number])\n       \n    #############################################################\n    \n    \n    ############### tag 채우기 ##################################\n    tag_counter = Counter()\n    for song in list(val_tmp.loc[i:i, 'songs'].values[0]):\n        if str(song) in song_tag_dict:\n            for tag in song_tag_dict[str(song)]:\n                tag_counter.update({tag : 1})\n    tag_counter = sorted(tag_counter.items(), key= lambda x:x[1], reverse = True)        \n    cur_tag = []\n    for k in tag_counter[:10]:\n        cur_tag.append(k[0])     \n    if (len(cur_tag) < 10) & (len(cur_tag) > 0 ):\n        ## 부족하면 채워준다.\n        update_tag = remove_seen(cur_tag, popular_date_tag[date]['tags'])\n        cur_tag.extend(update_tag)\n        cur_tag = cur_tag[:10]\n    if len(cur_tag) == 0:\n        cur_tag = popular_date_tag[date]['tags'][:10]\n        \n    #############################################################    \n    \n    \n    val1_predict.append({\n        \"id\" : list(val_tmp.loc[i:i, 'id'])[0],\n        \"songs\": remove_seen(list(val_tmp.loc[i:i, 'songs'])[0], cur_song)[:100],\n        \"tags\": cur_tag,\n    })\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## save file\nwrite_json(val1_predict, 'test1+3_'+str(small_years)+'.json')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n# start = time.time()  # 시작 시간 저장     \n# data = pd.concat([tmp, val_tmp])\n# data.reset_index(inplace = True, drop = True)\n\n# id2int = {u:i for i, u in enumerate((data['id']))}\n\n\n# print(\"merge data\", data.shape)\n\n# print('-------------------------')\n\n\n# ## 모든 point는 1임, 나중에\n# result = []\n# for i in range(len(data)):\n#     for song in data.loc[i:i, 'songs'].values[0]:\n#         df = pd.DataFrame({\n#                     'id' : [data.loc[i:i, 'id'].values[0]],\n#                     'song' : [song],\n#                     'point' : 1\n#                 })\n#         result += [df]\n\n# final_result = pd.concat(result)\n\n# del result, tmp, data, val_tmp\n# gc.collect()\n\n\n\n# tmp_dict = final_result['song'].value_counts().to_dict()\n\n# final_result['count']= final_result['song'].apply(lambda x : tmp_dict[x])\n# final_result = final_result[final_result['count'] > 1]\n\n\n# R_df = final_result.pivot(index = 'id', columns ='song', values = 'point').fillna(0)\n# del final_result\n\n# print(\"make cosine data\")    \n# cosine_array = cosine_similarity(R_df, R_df)\n# predicted_array = np.zeros(shape=(len(R_df.index),len(R_df.columns))) \n# for i in tqdm(range(len(cosine_array))):\n#     top_200 = cosine_array[i].argsort()[-201:][::-1]\n#     top_200 = np.delete(top_200, 0)\n\n#     weighted_sum = np.array([0])\n#     for top_idx in top_200:\n#         weighted_sum = weighted_sum + (cosine_array[i][top_idx] * R_df.values[top_idx])\n#     predicted = weighted_sum / len(top_200)\n#     predicted_array[i] = predicted\n# iu_predicted = R_df.values*(-99999) + predicted_array\n\n# print(\"make dic data\")    \n# cf_dic = {}\n# for i in range(len(iu_predicted)):\n#     cf_dic[R_df.index[i]] = R_df.columns[iu_predicted[i].argsort()[-200:][::-1]].tolist()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}